<!DOCTYPE html><html lang="en" class="__variable_3a0388 __variable_c1e5c9"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/66f30814ff6d7cdf.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/e11418ac562b8ac1-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/3c4d635f903201fc.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-352223f6443b9482.js"/><script src="/_next/static/chunks/4bd1b696-80bcaf75e1b4285e.js" async=""></script><script src="/_next/static/chunks/517-35c50d3e8bc7ba3e.js" async=""></script><script src="/_next/static/chunks/main-app-72bc0cc93300c503.js" async=""></script><script src="/_next/static/chunks/950-97be5dd3a7092b61.js" async=""></script><script src="/_next/static/chunks/app/layout-2d0d0aaaa8ede98d.js" async=""></script><link rel="preload" href="posthog.js" as="script"/><meta name="next-size-adjust"/><title>Machine Learning Multiscale Processes @ ICLR 2025</title><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="antialiased max-w-4xl mx-4 mt-8 lg:mx-auto"><main class="flex-auto min-w-0 mt-6 flex flex-col px-2 md:px-0"><aside class="-ml-[8px] mb-2 tracking-tight"><div class="lg:sticky lg:top-20"><nav class="flex flex-wrap flex-row items-start relative px-0 pb-0 fade md:overflow-auto scroll-pr-6 md:relative" id="nav"><div class="flex flex-wrap flex-row space-x-0 pr-10"><a class="transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1" href="/">MLMP ICLR 2025</a><a class="transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1" href="/dates">dates</a><a class="transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1" href="/call-for-papers">call for papers</a><a class="transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1" href="https://forms.gle/qQdyvGX6KXG1k2vz7">call for reviewers</a><a class="transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1" href="/keynote-speakers">keynote speakers</a><a class="transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1" href="/organizers">organizers</a><a class="transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1" href="/sponsors">sponsors</a><a class="transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1" href="/contact">contact</a></div></nav></div></aside><article class="prose prose-lg max-w-none hyphens-auto text-justify">
<h1 id="call-for-papers">Call for papers<a class="content-header" href="#call-for-papers">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h1>
<p>Please submit your paper through <a href="https://openreview.net/group?id=ICLR.cc/2025/Workshop/MLMP" rel="nofollow" target="_blank">OpenReview</a>. The deadline is February 10 2025, 23:59 AoE.</p>
<p>
  We are looking for contributions that will bring us closer to the building an AI that
  can advance from low–level theory and computationally–expensive simulation code to modeling
  complex systems on a useful time scale. All submissions will be evaluated based
  on their <em>relevance</em> to this goal.
</p>
<p>United by its goal, the workshop invites researchers working at all scales of nature: from the Planck length to the size of Universe, including quantum physics, chemistry, biology, materials science, mesoscopic physics, climate &#x26; weather, and astrophysics. We also look forward to cross–pollination of diverse methodologies: dimensionality reduction, manifold learning, Hamiltonian learning, PDE, ODE, symbolic reasoning, RL–based theory exploration, tuning computational models with experimental data, operator learning, physics–informed neural networks, surrogate modelling, digital twins, and more.</p>
<h2 id="tracks">Tracks<a class="content-header" href="#tracks">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h2>
<h3 id="new-scientific-result">New scientific result<a class="content-header" href="#new-scientific-result">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h3>
<p>
  A normal paper that presents a new scientific result. Such papers are evaluated on a balance of
  <em>novelty</em>, <em>significance</em>, and <em>technical quality</em>. Page limit is 6 pages. Publication of code and data is encouraged, but not mandatory. Reviewers are allowed to consider open source as a positive contribution to the study significance.
</p>
<h3 id="dataset-or-benchmark">Dataset or benchmark<a class="content-header" href="#dataset-or-benchmark">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h3>
<p>A work that presents a new dataset or benchmark – a way to measure progress in the field. Upon paper acceptance, the dataset must be open and available to the community; source code must be released under an <a href="https://opensource.org/licenses" rel="nofollow" target="_blank">OSI–approved license</a>. In terms of evaluation, <em>technical quality</em> and <em>significance</em> are the most important criteria. Page limit is 6 pages.</p>
<h3 id="findings-and-open-challenges">Findings and open challenges<a class="content-header" href="#findings-and-open-challenges">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h3>
<p>This is the track for <em>significance</em> and <em>novelty</em>. Submissions can have no code and experiments at all, but the authors still carry the burden to convince the reviewers that their ideas are worth exploring. We are looking for submissions introducing and discussing overlooked scientific questions and potential future directions for a given application area. We encourage submission that address open challenges and describe: 1. Why the current research and state-of-the-art fall short for a given challenges; 2. What directions the authors believe the community can focus on to help address the open challenge. Page limit is 6 pages. Track idea by <a href="https://sites.google.com/view/ai4mat/submissions" rel="nofollow" target="_blank">AI4AM</a></p>
<h3 id="engineering">Engineering<a class="content-header" href="#engineering">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h3>
<p>
  Working with complex systems requires good software engineering. In this track we are looking for
  contributions that introduce advancements in modelling software for complex systems. Contributions can be
  <em>tools</em>, <em>libraries</em>, <em>frameworks</em>, or <em>infrastructure</em>. The most important criteria are
  <em>technical quality</em> and <em>significance</em>. The code must be released under an <a href="https://opensource.org/licenses" rel="nofollow" target="_blank">OSI–approved license</a>. Page limit is 6 pages.
</p>
<h3 id="negative-result">Negative result<a class="content-header" href="#negative-result">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h3>
<p>A paper that presents a thorough experimental investigation of approaches which, despite considerable effort, did not improve over the current state-of-the-art methods. Submissions should detail the experimental design, document the encountered challenges, and provide a critical analysis of the negative findings along with lessons learned to guide future research. Emphasis is placed on <em>technical rigor</em>, <em>reproducibility</em>, and the broader impact of learning from failure. Page limit is 6 pages. Publication of code and data is encouraged, but not mandatory.</p>
<h3 id="short-paper">Short paper<a class="content-header" href="#short-paper">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h3>
<p>
  A less–than–full–conference paper that, for example, presents an implementation and evaluation of an unpublished but simple idea, a modest but self–contained theoretical result, a follow–up experiment or re–analysis of a previously published paper, or a fresh perspective on an existing publication. Or simply a work in progress. Such papers are evaluated on a balance of
  <em>novelty</em>, <em>significance</em>, and <em>technical quality</em>. Important differences from the “new scientific result” track are:
</p>
<ol>
  <li>Shorter page limit of 4 pages</li>
  <li>Lower acceptance bar</li>
  <li>Ineligible for the oral presentations</li>
  <li>The bar for spotlight presentations is the same as for the “new scientific result” track.</li>
  <li>Stricter dual submission policy: submissions to this track cannot be under review at any other venue at the time of submission</li>
</ol>
<h2 id="reproducible-research">Reproducible Research<a class="content-header" href="#reproducible-research">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h2>
<p>Good research is reusable and reproducible. Reviewers are encouraged to count the availability of the code and data for review as a positive contribution to the study significance and technical quality. Code wins arguments principle applies here, even though the original meaning was a bit different.</p>
<p>In order to streamline sharing, with generous support of our sponsor, we provide access to Constructor Platform, a cloud service. Its usage is not mandatory, the authors are free to share their code and data using any other service, provided they ensure the double–blindness. The main feature is that it allows the reviewers not only to read the code, but also to seamlessly run the code and explore the data from inside their web browser. Instructions:</p>
<ol>
  <li>Register using the <a href="https://constructor.app/portal/register?channel=platform&#x26;redirectUrl=/platform/projects&#x26;utm_source=iclr-2025-mlmp&#x26;utm_medium=referral&#x26;utm_campaign=iclr-2025-mlmp-review&#x26;utm_term=workshop&#x26;utm_content=registration-link" rel="nofollow" target="_blank">link</a>.</li>
  <li>Create a new project, put your code and data there. Set up the environment.</li>
  <li>Ensure double–blindness: do not include any information that can reveal the authors' identity. The platform will remove the git commit history, and platform–specific metadata before sharing the project with the reviewers.</li>
  <li>If you need more computational resources, such as GPU access, write to the Platform support “I need more computational resources for ICLR MLMP workshop”.</li>
  <li>When submitting the paper, provide the link to the project in the submission, e. g. <a href="https://constructor.app/platform/projects/254041652c5f422491b5b4b1584b760c/desks" rel="nofollow" target="_blank">https://constructor.app/platform/projects/254041652c5f422491b5b4b1584b760c/desks</a> There is no need to publish the project.</li>
  <li>Shortly after the deadline, a snapshot of the project will be taken and shared with the reviewers.</li>
  <li>You are then free to use Platform for further research.</li>
</ol>
<h2 id="general-policy">General Policy<a class="content-header" href="#general-policy">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h2>
<p>
  We welcome ongoing and unpublished work. We will reject work previously published in archiving venues.
  The definition of archiving venue follows the ICLR policy, e.g. arXiv is considered non–archiving, despite its name. We will however accept papers that are under review at any venue at the time of submission.
</p>
<p>Double blind reviewing. Submissions will be double blind: reviewers cannot see author names when conducting reviews, and authors cannot see reviewer names. Authors are responsible for anonymizing their submissions.</p>
<p>Submissions and reviews will not be public. Only accepted papers will be published on the workshop website, but still considered non–archival.</p>
<p>Format: All submissions must be in PDF format using the modified ICLR 2025 style (<a href="ICLR_2025_MLMP_Workshop.zip">file</a>, <a href="https://www.overleaf.com/read/wrsbgszhyntq#61c4bc" rel="nofollow" target="_blank">Overleaf</a>). It is almost identical to the main track templates, except for the lower page limit, and the header. References, acknowledgments, author contributions, and appendices do not count towards the page limit.</p>
<h2 id="financial-assistance">Financial assistance<a class="content-header" href="#financial-assistance">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h2>
<h3 id="central-iclr-financial-assistance">Central ICLR financial assistance<a class="content-header" href="#central-iclr-financial-assistance">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h3>
<p>This year, ICLR is discontinuing the separate “Tiny Papers” track, and is instead requiring each workshop to accept short (3–5 pages in ICLR format, exact page length to be determined by each workshop) paper submissions, with an eye towards inclusion; see ​​https://iclr.cc/Conferences/2025/CallForTinyPapers for more details. Authors of these papers will be earmarked for potential funding from ICLR, but need to submit a separate application for Financial Assistance that evaluates their eligibility. This application for Financial Assistance to attend ICLR 2025 will become available on https://iclr.cc/Conferences/2025/ at the beginning of February and close on March 2nd.</p>
<p>N. B. A workshop paper is a workshop paper for the purposes of funding – whatever track it is submitted to. Short papers have a lower threshold for acceptance, but do not per se provide higher probability of funding.</p>
<h3 id="workshopspecific-financial-assistance">Workshop–specific financial assistance<a class="content-header" href="#workshopspecific-financial-assistance">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h3>
<p>Due to the generous support of our sponsor, we will be able to provide some assistance to the authors of the accepted papers of the workshop. To apply, please indicate your interest in the submission form. The assistance is foreseen to be very limited, don't count on it as the main source of funding.</p>
<h2 id="other-ai-for-science-workshops-at-iclr-2025">Other AI for science workshops at ICLR 2025<a class="content-header" href="#other-ai-for-science-workshops-at-iclr-2025">
<span class="content-header-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5 linkicon">
        <path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path>
        <path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path>
      </svg></span></a></h2>
<p>If you feel that your work is not a good thematic fit for the multiscale ML workshop, consider submitting to one of the other AI for science workshops, such as:</p>
<ul>
  <li><a href="https://iclragenticai.github.io/" rel="nofollow" target="_blank">Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation</a></li>
  <li><a href="https://www.gembio.ai/" rel="nofollow" target="_blank">Generative and Experimental Perspectives for Biomolecular Design</a></li>
  <li><a href="https://ai4na-workshop.github.io/" rel="nofollow" target="_blank">Artificial Intelligence for Nucleic Acids</a></li>
  <li><a href="https://www.climatechange.ai/events/iclr2025" rel="nofollow" target="_blank">Tackling Climate Change with Machine Learning</a></li>
  <li><a href="https://mlgenx.github.io/" rel="nofollow" target="_blank">Machine Learning for Genomics Explorations (MLGenX)</a></li>
</ul>
</article><footer class="mb-16"><p class="mt-8 text-neutral-600 dark:text-neutral-300">© <!-- -->2025<!-- --> Nikita Kazeev &amp; Mengyi Chen, MIT Licensed</p></footer></main><script src="/_next/static/chunks/webpack-352223f6443b9482.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"4:\"$Sreact.fragment\"\n5:I[3704,[\"950\",\"static/chunks/950-97be5dd3a7092b61.js\",\"177\",\"static/chunks/app/layout-2d0d0aaaa8ede98d.js\"],\"\"]\n6:I[4839,[\"950\",\"static/chunks/950-97be5dd3a7092b61.js\",\"177\",\"static/chunks/app/layout-2d0d0aaaa8ede98d.js\"],\"\"]\n7:I[5244,[],\"\"]\n8:I[3866,[],\"\"]\na:I[6213,[],\"OutletBoundary\"]\nc:I[6213,[],\"MetadataBoundary\"]\ne:I[6213,[],\"ViewportBoundary\"]\n10:I[4835,[],\"\"]\n1:HL[\"/_next/static/media/66f30814ff6d7cdf.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/media/e11418ac562b8ac1-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/_next/static/css/3c4d635f903201fc.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"rAenBMf_KY3vL01eaf9df\",\"p\":\"\",\"c\":[\"\",\"call-for-papers\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"slug\",\"call-for-papers\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$4\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/3c4d635f903201fc.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_3a0388 __variable_c1e5c9\",\"children\":[[\"$\",\"$L5\",null,{\"src\":\"posthog.js\"}],[\"$\",\"body\",null,{\"className\":\"antialiased max-w-4xl mx-4 mt-8 lg:mx-auto\",\"children\":[\"$\",\"main\",null,{\"className\":\"flex-auto min-w-0 mt-6 flex flex-col px-2 md:px-0\",\"children\":[[\"$\",\"aside\",null,{\"className\":\"-ml-[8px] mb-2 tracking-tight\",\"children\":[\"$\",\"div\",null,{\"className\":\"lg:sticky lg:top-20\",\"children\":[\"$\",\"nav\",null,{\"className\":\"flex flex-wrap flex-row items-start relative px-0 pb-0 fade md:overflow-auto scroll-pr-6 md:relative\",\"id\":\"nav\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-wrap flex-row space-x-0 pr-10\",\"children\":[[\"$\",\"$L6\",\"/\",{\"href\":\"/\",\"className\":\"transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1\",\"children\":\"MLMP ICLR 2025\"}],[\"$\",\"$L6\",\"/dates\",{\"href\":\"/dates\",\"className\":\"transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1\",\"children\":\"dates\"}],[\"$\",\"$L6\",\"/call-for-papers\",{\"href\":\"/call-for-papers\",\"className\":\"transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1\",\"children\":\"call for papers\"}],[\"$\",\"$L6\",\"https://forms.gle/qQdyvGX6KXG1k2vz7\",{\"href\":\"https://forms.gle/qQdyvGX6KXG1k2vz7\",\"className\":\"transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1\",\"children\":\"call for reviewers\"}],[\"$\",\"$L6\",\"/keynote-speakers\",{\"href\":\"/keynote-speakers\",\"className\":\"transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1\",\"children\":\"keynote speakers\"}],[\"$\",\"$L6\",\"/organizers\",{\"href\":\"/organizers\",\"className\":\"transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1\",\"children\":\"organizers\"}],[\"$\",\"$L6\",\"/sponsors\",{\"href\":\"/sponsors\",\"className\":\"transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1\",\"children\":\"sponsors\"}],[\"$\",\"$L6\",\"/contact\",{\"href\":\"/contact\",\"className\":\"transition-all hover:text-neutral-800 dark:hover:text-neutral-200 flex align-middle relative py-1 px-2 m-1\",\"children\":\"contact\"}]]}]}]}]}],[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}],[\"$\",\"footer\",null,{\"className\":\"mb-16\",\"children\":[\"$\",\"p\",null,{\"className\":\"mt-8 text-neutral-600 dark:text-neutral-300\",\"children\":[\"© \",2025,\" Nikita Kazeev \u0026 Mengyi Chen, MIT Licensed\"]}]}]]}]}]]}]]}],{\"children\":[[\"slug\",\"call-for-papers\",\"d\"],[\"$\",\"$4\",\"c\",{\"children\":[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$0:f:0:1:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$4\",\"c\",{\"children\":[\"$L9\",null,[\"$\",\"$La\",null,{\"children\":\"$Lb\"}]]}],{},null]},null]},null],[\"$\",\"$4\",\"h\",{\"children\":[null,[\"$\",\"$4\",\"0bFiS1RAV-HKOI6edEq-9\",{\"children\":[[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],[\"$\",\"$Le\",null,{\"children\":\"$Lf\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\"}]]}]]}]]],\"m\":\"$undefined\",\"G\":[\"$10\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"11:T4ec9,"])</script><script>self.__next_f.push([1,"\n\u003ch1 id=\"call-for-papers\"\u003eCall for papers\u003ca class=\"content-header\" href=\"#call-for-papers\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003ePlease submit your paper through \u003ca href=\"https://openreview.net/group?id=ICLR.cc/2025/Workshop/MLMP\" rel=\"nofollow\" target=\"_blank\"\u003eOpenReview\u003c/a\u003e. The deadline is February 10 2025, 23:59 AoE.\u003c/p\u003e\n\u003cp\u003e\n  We are looking for contributions that will bring us closer to the building an AI that\n  can advance from low–level theory and computationally–expensive simulation code to modeling\n  complex systems on a useful time scale. All submissions will be evaluated based\n  on their \u003cem\u003erelevance\u003c/em\u003e to this goal.\n\u003c/p\u003e\n\u003cp\u003eUnited by its goal, the workshop invites researchers working at all scales of nature: from the Planck length to the size of Universe, including quantum physics, chemistry, biology, materials science, mesoscopic physics, climate \u0026#x26; weather, and astrophysics. We also look forward to cross–pollination of diverse methodologies: dimensionality reduction, manifold learning, Hamiltonian learning, PDE, ODE, symbolic reasoning, RL–based theory exploration, tuning computational models with experimental data, operator learning, physics–informed neural networks, surrogate modelling, digital twins, and more.\u003c/p\u003e\n\u003ch2 id=\"tracks\"\u003eTracks\u003ca class=\"content-header\" href=\"#tracks\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"new-scientific-result\"\u003eNew scientific result\u003ca class=\"content-header\" href=\"#new-scientific-result\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\n  A normal paper that presents a new scientific result. Such papers are evaluated on a balance of\n  \u003cem\u003enovelty\u003c/em\u003e, \u003cem\u003esignificance\u003c/em\u003e, and \u003cem\u003etechnical quality\u003c/em\u003e. Page limit is 6 pages. Publication of code and data is encouraged, but not mandatory. Reviewers are allowed to consider open source as a positive contribution to the study significance.\n\u003c/p\u003e\n\u003ch3 id=\"dataset-or-benchmark\"\u003eDataset or benchmark\u003ca class=\"content-header\" href=\"#dataset-or-benchmark\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eA work that presents a new dataset or benchmark – a way to measure progress in the field. Upon paper acceptance, the dataset must be open and available to the community; source code must be released under an \u003ca href=\"https://opensource.org/licenses\" rel=\"nofollow\" target=\"_blank\"\u003eOSI–approved license\u003c/a\u003e. In terms of evaluation, \u003cem\u003etechnical quality\u003c/em\u003e and \u003cem\u003esignificance\u003c/em\u003e are the most important criteria. Page limit is 6 pages.\u003c/p\u003e\n\u003ch3 id=\"findings-and-open-challenges\"\u003eFindings and open challenges\u003ca class=\"content-header\" href=\"#findings-and-open-challenges\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThis is the track for \u003cem\u003esignificance\u003c/em\u003e and \u003cem\u003enovelty\u003c/em\u003e. Submissions can have no code and experiments at all, but the authors still carry the burden to convince the reviewers that their ideas are worth exploring. We are looking for submissions introducing and discussing overlooked scientific questions and potential future directions for a given application area. We encourage submission that address open challenges and describe: 1. Why the current research and state-of-the-art fall short for a given challenges; 2. What directions the authors believe the community can focus on to help address the open challenge. Page limit is 6 pages. Track idea by \u003ca href=\"https://sites.google.com/view/ai4mat/submissions\" rel=\"nofollow\" target=\"_blank\"\u003eAI4AM\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"engineering\"\u003eEngineering\u003ca class=\"content-header\" href=\"#engineering\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\n  Working with complex systems requires good software engineering. In this track we are looking for\n  contributions that introduce advancements in modelling software for complex systems. Contributions can be\n  \u003cem\u003etools\u003c/em\u003e, \u003cem\u003elibraries\u003c/em\u003e, \u003cem\u003eframeworks\u003c/em\u003e, or \u003cem\u003einfrastructure\u003c/em\u003e. The most important criteria are\n  \u003cem\u003etechnical quality\u003c/em\u003e and \u003cem\u003esignificance\u003c/em\u003e. The code must be released under an \u003ca href=\"https://opensource.org/licenses\" rel=\"nofollow\" target=\"_blank\"\u003eOSI–approved license\u003c/a\u003e. Page limit is 6 pages.\n\u003c/p\u003e\n\u003ch3 id=\"negative-result\"\u003eNegative result\u003ca class=\"content-header\" href=\"#negative-result\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eA paper that presents a thorough experimental investigation of approaches which, despite considerable effort, did not improve over the current state-of-the-art methods. Submissions should detail the experimental design, document the encountered challenges, and provide a critical analysis of the negative findings along with lessons learned to guide future research. Emphasis is placed on \u003cem\u003etechnical rigor\u003c/em\u003e, \u003cem\u003ereproducibility\u003c/em\u003e, and the broader impact of learning from failure. Page limit is 6 pages. Publication of code and data is encouraged, but not mandatory.\u003c/p\u003e\n\u003ch3 id=\"short-paper\"\u003eShort paper\u003ca class=\"content-header\" href=\"#short-paper\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\n  A less–than–full–conference paper that, for example, presents an implementation and evaluation of an unpublished but simple idea, a modest but self–contained theoretical result, a follow–up experiment or re–analysis of a previously published paper, or a fresh perspective on an existing publication. Or simply a work in progress. Such papers are evaluated on a balance of\n  \u003cem\u003enovelty\u003c/em\u003e, \u003cem\u003esignificance\u003c/em\u003e, and \u003cem\u003etechnical quality\u003c/em\u003e. Important differences from the “new scientific result” track are:\n\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003eShorter page limit of 4 pages\u003c/li\u003e\n  \u003cli\u003eLower acceptance bar\u003c/li\u003e\n  \u003cli\u003eIneligible for the oral presentations\u003c/li\u003e\n  \u003cli\u003eThe bar for spotlight presentations is the same as for the “new scientific result” track.\u003c/li\u003e\n  \u003cli\u003eStricter dual submission policy: submissions to this track cannot be under review at any other venue at the time of submission\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"reproducible-research\"\u003eReproducible Research\u003ca class=\"content-header\" href=\"#reproducible-research\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eGood research is reusable and reproducible. Reviewers are encouraged to count the availability of the code and data for review as a positive contribution to the study significance and technical quality. Code wins arguments principle applies here, even though the original meaning was a bit different.\u003c/p\u003e\n\u003cp\u003eIn order to streamline sharing, with generous support of our sponsor, we provide access to Constructor Platform, a cloud service. Its usage is not mandatory, the authors are free to share their code and data using any other service, provided they ensure the double–blindness. The main feature is that it allows the reviewers not only to read the code, but also to seamlessly run the code and explore the data from inside their web browser. Instructions:\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003eRegister using the \u003ca href=\"https://constructor.app/portal/register?channel=platform\u0026#x26;redirectUrl=/platform/projects\u0026#x26;utm_source=iclr-2025-mlmp\u0026#x26;utm_medium=referral\u0026#x26;utm_campaign=iclr-2025-mlmp-review\u0026#x26;utm_term=workshop\u0026#x26;utm_content=registration-link\" rel=\"nofollow\" target=\"_blank\"\u003elink\u003c/a\u003e.\u003c/li\u003e\n  \u003cli\u003eCreate a new project, put your code and data there. Set up the environment.\u003c/li\u003e\n  \u003cli\u003eEnsure double–blindness: do not include any information that can reveal the authors' identity. The platform will remove the git commit history, and platform–specific metadata before sharing the project with the reviewers.\u003c/li\u003e\n  \u003cli\u003eIf you need more computational resources, such as GPU access, write to the Platform support “I need more computational resources for ICLR MLMP workshop”.\u003c/li\u003e\n  \u003cli\u003eWhen submitting the paper, provide the link to the project in the submission, e. g. \u003ca href=\"https://constructor.app/platform/projects/254041652c5f422491b5b4b1584b760c/desks\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://constructor.app/platform/projects/254041652c5f422491b5b4b1584b760c/desks\u003c/a\u003e There is no need to publish the project.\u003c/li\u003e\n  \u003cli\u003eShortly after the deadline, a snapshot of the project will be taken and shared with the reviewers.\u003c/li\u003e\n  \u003cli\u003eYou are then free to use Platform for further research.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"general-policy\"\u003eGeneral Policy\u003ca class=\"content-header\" href=\"#general-policy\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\n  We welcome ongoing and unpublished work. We will reject work previously published in archiving venues.\n  The definition of archiving venue follows the ICLR policy, e.g. arXiv is considered non–archiving, despite its name. We will however accept papers that are under review at any venue at the time of submission.\n\u003c/p\u003e\n\u003cp\u003eDouble blind reviewing. Submissions will be double blind: reviewers cannot see author names when conducting reviews, and authors cannot see reviewer names. Authors are responsible for anonymizing their submissions.\u003c/p\u003e\n\u003cp\u003eSubmissions and reviews will not be public. Only accepted papers will be published on the workshop website, but still considered non–archival.\u003c/p\u003e\n\u003cp\u003eFormat: All submissions must be in PDF format using the modified ICLR 2025 style (\u003ca href=\"ICLR_2025_MLMP_Workshop.zip\"\u003efile\u003c/a\u003e, \u003ca href=\"https://www.overleaf.com/read/wrsbgszhyntq#61c4bc\" rel=\"nofollow\" target=\"_blank\"\u003eOverleaf\u003c/a\u003e). It is almost identical to the main track templates, except for the lower page limit, and the header. References, acknowledgments, author contributions, and appendices do not count towards the page limit.\u003c/p\u003e\n\u003ch2 id=\"financial-assistance\"\u003eFinancial assistance\u003ca class=\"content-header\" href=\"#financial-assistance\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"central-iclr-financial-assistance\"\u003eCentral ICLR financial assistance\u003ca class=\"content-header\" href=\"#central-iclr-financial-assistance\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThis year, ICLR is discontinuing the separate “Tiny Papers” track, and is instead requiring each workshop to accept short (3–5 pages in ICLR format, exact page length to be determined by each workshop) paper submissions, with an eye towards inclusion; see ​​https://iclr.cc/Conferences/2025/CallForTinyPapers for more details. Authors of these papers will be earmarked for potential funding from ICLR, but need to submit a separate application for Financial Assistance that evaluates their eligibility. This application for Financial Assistance to attend ICLR 2025 will become available on https://iclr.cc/Conferences/2025/ at the beginning of February and close on March 2nd.\u003c/p\u003e\n\u003cp\u003eN. B. A workshop paper is a workshop paper for the purposes of funding – whatever track it is submitted to. Short papers have a lower threshold for acceptance, but do not per se provide higher probability of funding.\u003c/p\u003e\n\u003ch3 id=\"workshopspecific-financial-assistance\"\u003eWorkshop–specific financial assistance\u003ca class=\"content-header\" href=\"#workshopspecific-financial-assistance\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eDue to the generous support of our sponsor, we will be able to provide some assistance to the authors of the accepted papers of the workshop. To apply, please indicate your interest in the submission form. The assistance is foreseen to be very limited, don't count on it as the main source of funding.\u003c/p\u003e\n\u003ch2 id=\"other-ai-for-science-workshops-at-iclr-2025\"\u003eOther AI for science workshops at ICLR 2025\u003ca class=\"content-header\" href=\"#other-ai-for-science-workshops-at-iclr-2025\"\u003e\n\u003cspan class=\"content-header-link\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 20 20\" fill=\"currentColor\" class=\"w-5 h-5 linkicon\"\u003e\n        \u003cpath d=\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"\u003e\u003c/path\u003e\n        \u003cpath d=\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"\u003e\u003c/path\u003e\n      \u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eIf you feel that your work is not a good thematic fit for the multiscale ML workshop, consider submitting to one of the other AI for science workshops, such as:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ca href=\"https://iclragenticai.github.io/\" rel=\"nofollow\" target=\"_blank\"\u003eTowards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://www.gembio.ai/\" rel=\"nofollow\" target=\"_blank\"\u003eGenerative and Experimental Perspectives for Biomolecular Design\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://ai4na-workshop.github.io/\" rel=\"nofollow\" target=\"_blank\"\u003eArtificial Intelligence for Nucleic Acids\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://www.climatechange.ai/events/iclr2025\" rel=\"nofollow\" target=\"_blank\"\u003eTackling Climate Change with Machine Learning\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://mlgenx.github.io/\" rel=\"nofollow\" target=\"_blank\"\u003eMachine Learning for Genomics Explorations (MLGenX)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"article\",null,{\"className\":\"prose prose-lg max-w-none hyphens-auto text-justify\",\"dangerouslySetInnerHTML\":{\"__html\":\"$11\"}}]\n"])</script><script>self.__next_f.push([1,"f:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nd:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Machine Learning Multiscale Processes @ ICLR 2025\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"b:null\n"])</script></body></html>